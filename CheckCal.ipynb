{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-07T20:55:46.872708Z",
     "start_time": "2025-07-07T20:55:46.503965Z"
    }
   },
   "source": "import geopandas as gpd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T02:03:49.280729Z",
     "start_time": "2025-07-08T02:03:48.697237Z"
    }
   },
   "cell_type": "code",
   "source": "data = gpd.read_file(r\"C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Alabama\\Alabama BEAD Grid Analysis Layer.sqlite\")",
   "id": "588a7b137b5d1e29",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T02:03:49.308620Z",
     "start_time": "2025-07-08T02:03:49.301796Z"
    }
   },
   "cell_type": "code",
   "source": "data.head()",
   "id": "203e1bd51838924",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   index  point_count                                           geometry\n",
       "0      0            0  POLYGON ((-88.46548 30.22369, -88.46548 30.233...\n",
       "1      1            0  POLYGON ((-88.45548 30.22369, -88.45548 30.233...\n",
       "2      2            0  POLYGON ((-88.44548 30.22369, -88.44548 30.233...\n",
       "3      3            0  POLYGON ((-88.43548 30.22369, -88.43548 30.233...\n",
       "4      4            0  POLYGON ((-88.42548 30.22369, -88.42548 30.233..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>point_count</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-88.46548 30.22369, -88.46548 30.233...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-88.45548 30.22369, -88.45548 30.233...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-88.44548 30.22369, -88.44548 30.233...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-88.43548 30.22369, -88.43548 30.233...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-88.42548 30.22369, -88.42548 30.233...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T02:03:53.418961Z",
     "start_time": "2025-07-08T02:03:53.412959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the range dictionary\n",
    "range_dict = {\n",
    "    \"0\": {\"range\": (1, 5), \"color\": \"#e4e4f3\"},\n",
    "    \"1\": {\"range\": (5, 10), \"color\": \"#d1d1ea\"},\n",
    "    \"2\": {\"range\": (10, 20), \"color\": \"#b3b3e0\"},\n",
    "    \"3\": {\"range\": (20, 30), \"color\": \"#8080c5\"},\n",
    "    \"4\": {\"range\": (30, 50), \"color\": \"#6d6dbd\"},\n",
    "    \"5\": {\"range\": (50, 75), \"color\": \"#4949ac\"},\n",
    "    \"6\": {\"range\": (75, 100), \"color\": \"#3737a4\"},\n",
    "    \"7\": {\"range\": (100, 50000), \"color\": \"#121293\"},\n",
    "}"
   ],
   "id": "20ed164a56da89ca",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T02:03:55.186066Z",
     "start_time": "2025-07-08T02:03:54.863344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create detailed statistics and save to Excel (updated version)\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Function to classify point_count into range classes\n",
    "def classify_point_count(point_count):\n",
    "    for class_key, class_info in range_dict.items():\n",
    "        min_val, max_val = class_info[\"range\"]\n",
    "        if min_val <= point_count < max_val:\n",
    "            return class_key\n",
    "    return \"unclassified\"\n",
    "\n",
    "\n",
    "# Add classification column\n",
    "data['range_class'] = data['point_count'].apply(classify_point_count)\n",
    "\n",
    "# Create detailed statistics\n",
    "summary_data = []\n",
    "total_entries = len(data)\n",
    "total_point_count = data['point_count'].sum()\n",
    "\n",
    "for class_key, class_info in range_dict.items():\n",
    "    min_val, max_val = class_info[\"range\"]\n",
    "    class_data = data[data['range_class'] == class_key]\n",
    "    count = len(class_data)\n",
    "    percentage = (count / total_entries) * 100 if total_entries > 0 else 0\n",
    "\n",
    "    # Sum of point_count for this class\n",
    "    point_count_sum = class_data['point_count'].sum()\n",
    "    point_count_percentage = (point_count_sum / total_point_count) * 100 if total_point_count > 0 else 0\n",
    "\n",
    "    # Display range properly (subtract 1 from max for inclusive range display)\n",
    "    display_max = max_val - 1 if max_val != 50000 else \"50000+\"\n",
    "    range_display = f\"{min_val} - {display_max}\"\n",
    "\n",
    "    summary_data.append({\n",
    "        'Class': int(class_key),\n",
    "        'Range': range_display,\n",
    "        'Entry_Count': count,\n",
    "        'Entry_Percentage': round(percentage, 2),\n",
    "        'Point_Count_Sum': point_count_sum,\n",
    "        'Point_Count_Percentage': round(point_count_percentage, 2)\n",
    "    })\n",
    "\n",
    "# Handle unclassified entries\n",
    "unclassified_data = data[data['range_class'] == 'unclassified']\n",
    "if len(unclassified_data) > 0:\n",
    "    count = len(unclassified_data)\n",
    "    percentage = (count / total_entries) * 100\n",
    "    point_count_sum = unclassified_data['point_count'].sum()\n",
    "    point_count_percentage = (point_count_sum / total_point_count) * 100 if total_point_count > 0 else 0\n",
    "\n",
    "    summary_data.append({\n",
    "        'Class': 'Unclassified',\n",
    "        'Range': 'Outside defined ranges',\n",
    "        'Entry_Count': count,\n",
    "        'Entry_Percentage': round(percentage, 2),\n",
    "        'Point_Count_Sum': point_count_sum,\n",
    "        'Point_Count_Percentage': round(point_count_percentage, 2)\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"Summary Statistics:\")\n",
    "print(summary_df)\n",
    "print(f\"\\nTotal entries: {total_entries}\")\n",
    "print(f\"Total point count: {total_point_count}\")"
   ],
   "id": "c782ac8eb6ad0b32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics:\n",
      "          Class                   Range  Entry_Count  Entry_Percentage  \\\n",
      "0             0                   1 - 4        21035             12.44   \n",
      "1             1                   5 - 9         5525              3.27   \n",
      "2             2                 10 - 19         3024              1.79   \n",
      "3             3                 20 - 29          781              0.46   \n",
      "4             4                 30 - 49          444              0.26   \n",
      "5             5                 50 - 74          156              0.09   \n",
      "6             6                 75 - 99           63              0.04   \n",
      "7             7            100 - 50000+           69              0.04   \n",
      "8  Unclassified  Outside defined ranges       137990             81.61   \n",
      "\n",
      "   Point_Count_Sum  Point_Count_Percentage  \n",
      "0            39132                   22.22  \n",
      "1            36275                   20.60  \n",
      "2            40120                   22.78  \n",
      "3            18468                   10.49  \n",
      "4            16644                    9.45  \n",
      "5             9337                    5.30  \n",
      "6             5306                    3.01  \n",
      "7            10844                    6.16  \n",
      "8                0                    0.00  \n",
      "\n",
      "Total entries: 169087\n",
      "Total point count: 176126\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T02:03:56.559055Z",
     "start_time": "2025-07-08T02:03:56.524578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save to Excel with proper formatting (updated version)\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# Create workbook and worksheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"Point Count Analysis\"\n",
    "\n",
    "# Add title\n",
    "ws['A1'] = \"Point Count Distribution Analysis\"\n",
    "ws['A1'].font = Font(bold=True, size=16)\n",
    "ws['A1'].alignment = Alignment(horizontal='center')\n",
    "ws.merge_cells('A1:F1')\n",
    "\n",
    "# Add summary info\n",
    "ws['A3'] = f\"Total Entries (1 Km Sq. Grid]: {total_entries}\"\n",
    "ws['A3'].font = Font(bold=True)\n",
    "ws['A4'] = f\"Total BSL Count: {total_point_count}\"\n",
    "ws['A4'].font = Font(bold=True)\n",
    "ws['A5'] = f\"Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d')}\"\n",
    "\n",
    "# Add headers starting from row 7\n",
    "headers = ['Class', 'Range', 'Entry Count', 'Entry Percentage (%)', 'Point Count Sum', 'Point Count Percentage (%)']\n",
    "for col, header in enumerate(headers, 1):\n",
    "    cell = ws.cell(row=7, column=col, value=header)\n",
    "    cell.font = Font(bold=True)\n",
    "    cell.fill = PatternFill(start_color='D3D3D3', end_color='D3D3D3', fill_type='solid')\n",
    "    cell.alignment = Alignment(horizontal='center')\n",
    "\n",
    "# Add data\n",
    "for row_idx, (_, row) in enumerate(summary_df.iterrows(), 8):\n",
    "    ws.cell(row=row_idx, column=1, value=row['Class'])\n",
    "    ws.cell(row=row_idx, column=2, value=row['Range'])\n",
    "    ws.cell(row=row_idx, column=3, value=row['Entry_Count'])\n",
    "    ws.cell(row=row_idx, column=4, value=row['Entry_Percentage'])\n",
    "    ws.cell(row=row_idx, column=5, value=row['Point_Count_Sum'])\n",
    "    ws.cell(row=row_idx, column=6, value=row['Point_Count_Percentage'])\n",
    "\n",
    "# Auto-adjust column widths\n",
    "for col_num in range(1, 7):  # Columns A to F\n",
    "    max_length = 0\n",
    "    column_letter = get_column_letter(col_num)\n",
    "\n",
    "    # Check all cells in this column\n",
    "    for row_num in range(1, ws.max_row + 1):\n",
    "        cell = ws.cell(row=row_num, column=col_num)\n",
    "        try:\n",
    "            if cell.value and len(str(cell.value)) > max_length:\n",
    "                max_length = len(str(cell.value))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Set column width\n",
    "    adjusted_width = min(max_length + 2, 25)\n",
    "    ws.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "# Add borders\n",
    "thin_border = Border(\n",
    "    left=Side(style='thin'),\n",
    "    right=Side(style='thin'),\n",
    "    top=Side(style='thin'),\n",
    "    bottom=Side(style='thin')\n",
    ")\n",
    "\n",
    "for row in ws.iter_rows(min_row=7, max_row=7 + len(summary_df), min_col=1, max_col=6):\n",
    "    for cell in row:\n",
    "        cell.border = thin_border\n",
    "        # Center align numeric columns\n",
    "        if cell.column in [1, 3, 4, 5, 6]:\n",
    "            cell.alignment = Alignment(horizontal='center')\n",
    "\n",
    "# Save the file\n",
    "excel_filename = \"point_count_analysis.xlsx\"\n",
    "wb.save(excel_filename)\n",
    "print(f\"\\nExcel file saved as: {excel_filename}\")"
   ],
   "id": "b82382ed4b934cb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Excel file saved as: point_count_analysis.xlsx\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T02:04:04.175768Z",
     "start_time": "2025-07-08T02:04:02.914970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# Load data\n",
    "data = gpd.read_file(r\"C:\\Users\\meloy\\PycharmProjects\\WebGisGeneratorV1\\Data\\Missouri\\Missouri BEAD Grid Analysis Layer.sqlite\")\n",
    "\n",
    "# Define ranges\n",
    "range_dict = {\n",
    "    \"0\": {\"range\": (1, 5), \"color\": \"#e4e4f3\"},\n",
    "    \"1\": {\"range\": (5, 10), \"color\": \"#d1d1ea\"},\n",
    "    \"2\": {\"range\": (10, 20), \"color\": \"#b3b3e0\"},\n",
    "    \"3\": {\"range\": (20, 30), \"color\": \"#8080c5\"},\n",
    "    \"4\": {\"range\": (30, 50), \"color\": \"#6d6dbd\"},\n",
    "    \"5\": {\"range\": (50, 75), \"color\": \"#4949ac\"},\n",
    "    \"6\": {\"range\": (75, 100), \"color\": \"#3737a4\"},\n",
    "    \"7\": {\"range\": (100, 50000), \"color\": \"#121293\"},\n",
    "}\n",
    "\n",
    "def classify_point_count(point_count):\n",
    "    for class_key, class_info in range_dict.items():\n",
    "        min_val, max_val = class_info[\"range\"]\n",
    "        if min_val <= point_count < max_val:\n",
    "            return class_key\n",
    "    return \"unclassified\"\n",
    "\n",
    "# Classify\n",
    "data['range_class'] = data['point_count'].apply(classify_point_count)\n",
    "total_entries = len(data)\n",
    "total_point_count = data['point_count'].sum()\n",
    "\n",
    "# Prepare summary\n",
    "summary_data = []\n",
    "for class_key, class_info in range_dict.items():\n",
    "    min_val, max_val = class_info[\"range\"]\n",
    "    class_data = data[data['range_class'] == class_key]\n",
    "    count = len(class_data)\n",
    "    percentage = (count / total_entries) * 100\n",
    "    point_count_sum = class_data['point_count'].sum()\n",
    "    point_count_percentage = (point_count_sum / total_point_count) * 100\n",
    "    display_max = max_val - 1 if max_val != 50000 else \"50000+\"\n",
    "    range_display = f\"{min_val} - {display_max}\"\n",
    "    average = round(point_count_sum / count) if count > 0 else None\n",
    "\n",
    "    summary_data.append({\n",
    "        'Class': int(class_key),\n",
    "        'Range': range_display,\n",
    "        'Entry Count (1 Sq Km Grids)': count,\n",
    "        'Entry Percentage (%)': f\"{round(percentage, 1)}%\",\n",
    "        'Point Count (BSLs) Sum': point_count_sum,\n",
    "        'Point Count Percentage (%)': f\"{round(point_count_percentage, 1)}%\",\n",
    "        'Average Locations per Box': average\n",
    "    })\n",
    "\n",
    "# Add unclassified\n",
    "unclassified_data = data[data['range_class'] == 'unclassified']\n",
    "if len(unclassified_data) > 0:\n",
    "    count = len(unclassified_data)\n",
    "    percentage = (count / total_entries) * 100\n",
    "    summary_data.append({\n",
    "        'Class': 'Unclassified',\n",
    "        'Range': 'Zero Locations',\n",
    "        'Entry Count (1 Sq Km Grids)': count,\n",
    "        'Entry Percentage (%)': f\"{round(percentage, 1)}%\",\n",
    "        'Point Count (BSLs) Sum': None,\n",
    "        'Point Count Percentage (%)': None,\n",
    "        'Average Locations per Box': None\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Write to Excel\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"Point Count Analysis\"\n",
    "\n",
    "# Title\n",
    "ws.merge_cells('A1:G1')\n",
    "ws['A1'] = \"Point Count Distribution Analysis\"\n",
    "ws['A1'].font = Font(bold=True, size=14)\n",
    "ws['A1'].alignment = Alignment(horizontal='center')\n",
    "\n",
    "# Header Info\n",
    "ws['A3'] = \"Missouri\"\n",
    "ws['A4'] = f\"Total Entries (1 km sq Grids): {total_entries:,}\"\n",
    "ws['A4'].font = Font(bold=True)\n",
    "ws['A5'] = f\"Total Point Count (BSL): {total_point_count:,}\"\n",
    "ws['A5'].font = Font(bold=True)\n",
    "ws['A6'] = f\"Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d')}\"\n",
    "\n",
    "# Headers\n",
    "headers = list(summary_df.columns)\n",
    "for col_idx, header in enumerate(headers, start=1):\n",
    "    cell = ws.cell(row=8, column=col_idx, value=header)\n",
    "    cell.font = Font(bold=True)\n",
    "    cell.fill = PatternFill(start_color='D3D3D3', end_color='D3D3D3', fill_type='solid')\n",
    "    cell.alignment = Alignment(horizontal='center')\n",
    "\n",
    "# Data\n",
    "for row_idx, row in enumerate(summary_df.itertuples(index=False), start=9):\n",
    "    for col_idx, value in enumerate(row, start=1):\n",
    "        cell = ws.cell(row=row_idx, column=col_idx, value=value)\n",
    "\n",
    "        # Comma formatting\n",
    "        if headers[col_idx - 1] in ['Entry Count (1 Sq Km Grids)', 'Point Count (BSLs) Sum', 'Average Locations per Box'] and isinstance(value, (int, float)):\n",
    "            cell.number_format = '#,##0'\n",
    "\n",
    "        # Center align all cells\n",
    "        cell.alignment = Alignment(horizontal='center')\n",
    "\n",
    "# Auto-fit columns\n",
    "for col_idx in range(1, len(headers) + 1):\n",
    "    max_length = 0\n",
    "    column_letter = get_column_letter(col_idx)\n",
    "    for row in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=col_idx, max_col=col_idx):\n",
    "        for cell in row:\n",
    "            if cell.value:\n",
    "                max_length = max(max_length, len(str(cell.value)))\n",
    "    ws.column_dimensions[column_letter].width = min(max_length + 2, 30)\n",
    "\n",
    "# Add borders\n",
    "thin_border = Border(left=Side(style='thin'), right=Side(style='thin'),\n",
    "                     top=Side(style='thin'), bottom=Side(style='thin'))\n",
    "for row in ws.iter_rows(min_row=8, max_row=8 + len(summary_df), min_col=1, max_col=len(headers)):\n",
    "    for cell in row:\n",
    "        cell.border = thin_border\n",
    "\n",
    "# Save\n",
    "wb.save(\"point_count_analysis_formatted.xlsx\")\n",
    "print(\"Excel file saved as: point_count_analysis_formatted.xlsx\")"
   ],
   "id": "53de09f6f1de24e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved as: point_count_analysis_formatted.xlsx\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T02:08:05.513416Z",
     "start_time": "2025-07-08T02:07:14.240765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# Define the folder containing all state subfolders\n",
    "root_dir = r\"C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\"\n",
    "\n",
    "# Define range dictionary once\n",
    "range_dict = {\n",
    "    \"0\": {\"range\": (1, 5)},\n",
    "    \"1\": {\"range\": (5, 10)},\n",
    "    \"2\": {\"range\": (10, 20)},\n",
    "    \"3\": {\"range\": (20, 30)},\n",
    "    \"4\": {\"range\": (30, 50)},\n",
    "    \"5\": {\"range\": (50, 75)},\n",
    "    \"6\": {\"range\": (75, 100)},\n",
    "    \"7\": {\"range\": (100, 50000)},\n",
    "}\n",
    "\n",
    "# Classification function\n",
    "def classify_point_count(point_count):\n",
    "    for class_key, class_info in range_dict.items():\n",
    "        min_val, max_val = class_info[\"range\"]\n",
    "        if min_val <= point_count < max_val:\n",
    "            return class_key\n",
    "    return \"unclassified\"\n",
    "\n",
    "# Process each state folder\n",
    "for state_name in os.listdir(root_dir):\n",
    "    state_path = os.path.join(root_dir, state_name)\n",
    "    if not os.path.isdir(state_path):\n",
    "        continue\n",
    "\n",
    "    # Find the .sqlite file inside the folder\n",
    "    sqlite_files = [f for f in os.listdir(state_path) if f.endswith(\".sqlite\") and f.startswith(f\"{state_name} BEAD Grid Analysis Layer\")]\n",
    "    if not sqlite_files:\n",
    "        print(f\"[SKIPPED] No .sqlite file found in {state_name}\")\n",
    "        continue\n",
    "\n",
    "    sqlite_path = os.path.join(state_path, sqlite_files[0])\n",
    "    print(f\"[PROCESSING] {state_name} — {sqlite_files[0]}\")\n",
    "\n",
    "    try:\n",
    "        # Load data\n",
    "        data = gpd.read_file(sqlite_path)\n",
    "        # print(data.head())\n",
    "        data['range_class'] = data['point_count'].apply(classify_point_count)\n",
    "\n",
    "        total_entries = len(data)\n",
    "        total_point_count = data['point_count'].sum()\n",
    "\n",
    "        summary_data = []\n",
    "        for class_key, class_info in range_dict.items():\n",
    "            min_val, max_val = class_info[\"range\"]\n",
    "            class_data = data[data['range_class'] == class_key]\n",
    "            count = len(class_data)\n",
    "            percentage = (count / total_entries) * 100\n",
    "            point_count_sum = class_data['point_count'].sum()\n",
    "            point_count_percentage = (point_count_sum / total_point_count) * 100\n",
    "            display_max = max_val - 1 if max_val != 50000 else \"50000+\"\n",
    "            range_display = f\"{min_val} - {display_max}\"\n",
    "            average = round(point_count_sum / count) if count > 0 else None\n",
    "\n",
    "            summary_data.append({\n",
    "                'Class': int(class_key),\n",
    "                'Range': range_display,\n",
    "                'Entry Count (1 Sq Km Grids)': count,\n",
    "                'Entry Percentage (%)': f\"{round(percentage, 1)}%\",\n",
    "                'Point Count (BSLs) Sum': point_count_sum,\n",
    "                'Point Count Percentage (%)': f\"{round(point_count_percentage, 1)}%\",\n",
    "                'Average Locations per Box': average\n",
    "            })\n",
    "\n",
    "        # Add unclassified\n",
    "        unclassified_data = data[data['range_class'] == 'unclassified']\n",
    "        if len(unclassified_data) > 0:\n",
    "            count = len(unclassified_data)\n",
    "            percentage = (count / total_entries) * 100\n",
    "            summary_data.append({\n",
    "                'Class': 'Unclassified',\n",
    "                'Range': 'Zero Locations',\n",
    "                'Entry Count (1 Sq Km Grids)': count,\n",
    "                'Entry Percentage (%)': f\"{round(percentage, 1)}%\",\n",
    "                'Point Count (BSLs) Sum': None,\n",
    "                'Point Count Percentage (%)': None,\n",
    "                'Average Locations per Box': None\n",
    "            })\n",
    "\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "        # Create Excel\n",
    "        wb = Workbook()\n",
    "        ws = wb.active\n",
    "        ws.title = \"Point Count Analysis\"\n",
    "        ws.merge_cells('A1:G1')\n",
    "        ws['A1'] = \"Point Count Distribution Analysis\"\n",
    "        ws['A1'].font = Font(bold=True, size=14)\n",
    "        ws['A1'].alignment = Alignment(horizontal='center')\n",
    "\n",
    "        ws['A3'] = state_name\n",
    "        ws['A4'] = f\"Total Entries (1 km sq Grids): {total_entries:,}\"\n",
    "        ws['A4'].font = Font(bold=True)\n",
    "        ws['A5'] = f\"Total Point Count (BSL): {total_point_count:,}\"\n",
    "        ws['A5'].font = Font(bold=True)\n",
    "        ws['A6'] = f\"Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d')}\"\n",
    "\n",
    "        headers = list(summary_df.columns)\n",
    "        for col_idx, header in enumerate(headers, start=1):\n",
    "            cell = ws.cell(row=8, column=col_idx, value=header)\n",
    "            cell.font = Font(bold=True)\n",
    "            cell.fill = PatternFill(start_color='D3D3D3', end_color='D3D3D3', fill_type='solid')\n",
    "            cell.alignment = Alignment(horizontal='center')\n",
    "\n",
    "        for row_idx, row in enumerate(summary_df.itertuples(index=False), start=9):\n",
    "            for col_idx, value in enumerate(row, start=1):\n",
    "                cell = ws.cell(row=row_idx, column=col_idx, value=value)\n",
    "                if headers[col_idx - 1] in ['Entry Count (1 Sq Km Grids)', 'Point Count (BSLs) Sum', 'Average Locations per Box'] and isinstance(value, (int, float)):\n",
    "                    cell.number_format = '#,##0'\n",
    "                cell.alignment = Alignment(horizontal='center')\n",
    "\n",
    "        # Auto-fit columns\n",
    "        for col_idx in range(1, len(headers) + 1):\n",
    "            max_length = 0\n",
    "            column_letter = get_column_letter(col_idx)\n",
    "            for row in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=col_idx, max_col=col_idx):\n",
    "                for cell in row:\n",
    "                    if cell.value:\n",
    "                        max_length = max(max_length, len(str(cell.value)))\n",
    "            ws.column_dimensions[column_letter].width = min(max_length + 2, 30)\n",
    "\n",
    "        thin_border = Border(left=Side(style='thin'), right=Side(style='thin'),\n",
    "                             top=Side(style='thin'), bottom=Side(style='thin'))\n",
    "        for row in ws.iter_rows(min_row=8, max_row=8 + len(summary_df), min_col=1, max_col=len(headers)):\n",
    "            for cell in row:\n",
    "                cell.border = thin_border\n",
    "\n",
    "        # Save Excel in same folder\n",
    "        output_path = os.path.join(state_path, \"point_count_analysis.xlsx\")\n",
    "        wb.save(output_path)\n",
    "        print(f\"[SAVED] {state_name} → {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to process {state_name}: {e}\")\n"
   ],
   "id": "3b3184beda1a88cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROCESSING] Alabama — Alabama BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Alabama → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Alabama\\point_count_analysis.xlsx\n",
      "[SKIPPED] No .sqlite file found in Alaska\n",
      "[PROCESSING] Arizona — Arizona BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Arizona → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Arizona\\point_count_analysis.xlsx\n",
      "[PROCESSING] Arkansas — Arkansas BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Arkansas → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Arkansas\\point_count_analysis.xlsx\n",
      "[PROCESSING] California — California BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] California → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\California\\point_count_analysis.xlsx\n",
      "[PROCESSING] Colorado — Colorado BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Colorado → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Colorado\\point_count_analysis.xlsx\n",
      "[PROCESSING] Connecticut — Connecticut BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Connecticut → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Connecticut\\point_count_analysis.xlsx\n",
      "[PROCESSING] Delaware — Delaware BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Delaware → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Delaware\\point_count_analysis.xlsx\n",
      "[PROCESSING] Florida — Florida BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Florida → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Florida\\point_count_analysis.xlsx\n",
      "[PROCESSING] Georgia — Georgia BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Georgia → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Georgia\\point_count_analysis.xlsx\n",
      "[PROCESSING] Hawaii — Hawaii BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Hawaii → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Hawaii\\point_count_analysis.xlsx\n",
      "[PROCESSING] Idaho — Idaho BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Idaho → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Idaho\\point_count_analysis.xlsx\n",
      "[PROCESSING] Illinois — Illinois BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Illinois → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Illinois\\point_count_analysis.xlsx\n",
      "[PROCESSING] Indiana — Indiana BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Indiana → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Indiana\\point_count_analysis.xlsx\n",
      "[PROCESSING] Iowa — Iowa BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Iowa → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Iowa\\point_count_analysis.xlsx\n",
      "[PROCESSING] Kansas — Kansas BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Kansas → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Kansas\\point_count_analysis.xlsx\n",
      "[PROCESSING] Kentucky — Kentucky BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Kentucky → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Kentucky\\point_count_analysis.xlsx\n",
      "[PROCESSING] Louisiana — Louisiana BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Louisiana → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Louisiana\\point_count_analysis.xlsx\n",
      "[PROCESSING] Maine — Maine BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Maine → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Maine\\point_count_analysis.xlsx\n",
      "[PROCESSING] Maryland — Maryland BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Maryland → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Maryland\\point_count_analysis.xlsx\n",
      "[PROCESSING] Massachusetts — Massachusetts BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Massachusetts → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Massachusetts\\point_count_analysis.xlsx\n",
      "[PROCESSING] Michigan — Michigan BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Michigan → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Michigan\\point_count_analysis.xlsx\n",
      "[PROCESSING] Minnesota — Minnesota BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Minnesota → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Minnesota\\point_count_analysis.xlsx\n",
      "[PROCESSING] Mississippi — Mississippi BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Mississippi → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Mississippi\\point_count_analysis.xlsx\n",
      "[PROCESSING] Missouri — Missouri BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Missouri → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Missouri\\point_count_analysis.xlsx\n",
      "[PROCESSING] Montana — Montana BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Montana → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Montana\\point_count_analysis.xlsx\n",
      "[PROCESSING] Nebraska — Nebraska BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Nebraska → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Nebraska\\point_count_analysis.xlsx\n",
      "[PROCESSING] Nevada — Nevada BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Nevada → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Nevada\\point_count_analysis.xlsx\n",
      "[PROCESSING] New Hampshire — New Hampshire BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] New Hampshire → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\New Hampshire\\point_count_analysis.xlsx\n",
      "[PROCESSING] New Jersey — New Jersey BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] New Jersey → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\New Jersey\\point_count_analysis.xlsx\n",
      "[PROCESSING] New Mexico — New Mexico BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] New Mexico → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\New Mexico\\point_count_analysis.xlsx\n",
      "[PROCESSING] New York — New York BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] New York → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\New York\\point_count_analysis.xlsx\n",
      "[PROCESSING] North Carolina — North Carolina BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] North Carolina → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\North Carolina\\point_count_analysis.xlsx\n",
      "[PROCESSING] North Dakota — North Dakota BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] North Dakota → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\North Dakota\\point_count_analysis.xlsx\n",
      "[PROCESSING] Ohio — Ohio BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Ohio → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Ohio\\point_count_analysis.xlsx\n",
      "[PROCESSING] Oklahoma — Oklahoma BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Oklahoma → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Oklahoma\\point_count_analysis.xlsx\n",
      "[PROCESSING] Oregon — Oregon BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Oregon → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Oregon\\point_count_analysis.xlsx\n",
      "[PROCESSING] Pennsylvania — Pennsylvania BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Pennsylvania → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Pennsylvania\\point_count_analysis.xlsx\n",
      "[PROCESSING] Rhode Island — Rhode Island BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Rhode Island → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Rhode Island\\point_count_analysis.xlsx\n",
      "[PROCESSING] South Carolina — South Carolina BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] South Carolina → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\South Carolina\\point_count_analysis.xlsx\n",
      "[PROCESSING] South Dakota — South Dakota BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] South Dakota → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\South Dakota\\point_count_analysis.xlsx\n",
      "[PROCESSING] Tennessee — Tennessee BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Tennessee → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Tennessee\\point_count_analysis.xlsx\n",
      "[PROCESSING] Texas — Texas BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Texas → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Texas\\point_count_analysis.xlsx\n",
      "[PROCESSING] Utah — Utah BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Utah → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Utah\\point_count_analysis.xlsx\n",
      "[PROCESSING] Vermont — Vermont BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Vermont → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Vermont\\point_count_analysis.xlsx\n",
      "[PROCESSING] Virginia — Virginia BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Virginia → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Virginia\\point_count_analysis.xlsx\n",
      "[PROCESSING] Washington — Washington BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Washington → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Washington\\point_count_analysis.xlsx\n",
      "[PROCESSING] West Virginia — West Virginia BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] West Virginia → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\West Virginia\\point_count_analysis.xlsx\n",
      "[PROCESSING] Wisconsin — Wisconsin BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Wisconsin → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Wisconsin\\point_count_analysis.xlsx\n",
      "[PROCESSING] Wyoming — Wyoming BEAD Grid Analysis Layer.sqlite\n",
      "[SAVED] Wyoming → C:\\Users\\meloy\\SW2020 Dropbox\\SW2020\\Workspaces\\Narek_Meloyan\\Tarana Project\\Data-Structured\\Wyoming\\point_count_analysis.xlsx\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e752d2081ebe15fa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
